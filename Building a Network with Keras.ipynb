{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Build a Regression Model in Keras\n",
    "by Jacques Jansen van Rensburg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data file\n",
    "Since it is the same Data that we used in the Labs Session of Week 3, I just Copy and Paste the url that we used then for convenience sake.\n",
    "I also know from the Labs session that the Data set is clean and ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into predictors and target\n",
    "The target variable in this problem is the concrete sample strength. Therefore, our predictors will be all the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = df.columns\n",
    "\n",
    "predictors = df[df_columns[df_columns != 'Strength']]\n",
    "target = df['Strength']\n",
    "\n",
    "cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Build a Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now use the  Keras library to build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a neural network with one hidden layer of 10 nodes, and a ReLU activation function.\n",
    "And then Use the adam optimizer and the mean squared error as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(cols,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_splithelper function from Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:       Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
      "774   382.0                 0.0      0.0  186.0               0.0   \n",
      "407   165.0               128.5    132.1  175.1               8.1   \n",
      "620   254.0                 0.0      0.0  198.0               0.0   \n",
      "479   446.0                24.0     79.0  162.0              11.6   \n",
      "530   359.0                19.0    141.0  154.0              10.9   \n",
      "..      ...                 ...      ...    ...               ...   \n",
      "575   238.1                 0.0      0.0  185.7               0.0   \n",
      "973   143.8               136.3    106.2  178.1               7.5   \n",
      "75    475.0               118.8      0.0  181.1               8.9   \n",
      "599   339.0                 0.0      0.0  197.0               0.0   \n",
      "863   288.0               121.0      0.0  177.0               7.0   \n",
      "\n",
      "     Coarse Aggregate  Fine Aggregate  Age  \n",
      "774            1111.0           784.0    7  \n",
      "407            1005.8           746.6    3  \n",
      "620             968.0           863.0  365  \n",
      "479             967.0           712.0    7  \n",
      "530             942.0           801.0   56  \n",
      "..                ...             ...  ...  \n",
      "575            1118.8           789.3   28  \n",
      "973             941.5           774.3   28  \n",
      "75              852.1           781.5    3  \n",
      "599             968.0           781.0    7  \n",
      "863             908.0           829.0   28  \n",
      "\n",
      "[721 rows x 8 columns]\n",
      "y_train:  774    11.47\n",
      "407    19.42\n",
      "620    29.79\n",
      "479    38.02\n",
      "530    66.78\n",
      "       ...  \n",
      "575    17.58\n",
      "973    26.15\n",
      "75     37.80\n",
      "599    20.97\n",
      "863    42.13\n",
      "Name: Strength, Length: 721, dtype: float64\n",
      "X_test:       Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
      "605   236.0                 0.0      0.0  194.0               0.0   \n",
      "572   220.8               147.2      0.0  185.7               0.0   \n",
      "920   136.0               162.0    126.0  172.0              10.0   \n",
      "921   155.0                 0.0    143.0  193.0               9.0   \n",
      "74    375.0                93.8      0.0  126.6              23.4   \n",
      "..      ...                 ...      ...    ...               ...   \n",
      "872   261.0               100.0     78.0  201.0               9.0   \n",
      "931   144.0                15.0    195.0  176.0               6.0   \n",
      "27    342.0                38.0      0.0  228.0               0.0   \n",
      "749   500.0                 0.0      0.0  200.0               0.0   \n",
      "522   284.0                15.0    141.0  179.0               5.5   \n",
      "\n",
      "     Coarse Aggregate  Fine Aggregate  Age  \n",
      "605             968.0           885.0    3  \n",
      "572            1055.0           744.3    7  \n",
      "920             923.0           764.0   28  \n",
      "921             877.0           868.0   28  \n",
      "74              852.1           992.6    3  \n",
      "..                ...             ...  ...  \n",
      "872             864.0           761.0   28  \n",
      "931            1021.0           709.0   28  \n",
      "27              932.0           670.0  180  \n",
      "749            1125.0           613.0   14  \n",
      "522             842.0           801.0   56  \n",
      "\n",
      "[309 rows x 8 columns]\n",
      "y_test:  605     6.47\n",
      "572    13.09\n",
      "920    29.07\n",
      "921     9.74\n",
      "74     29.00\n",
      "       ...  \n",
      "872    32.40\n",
      "931    15.34\n",
      "27     52.12\n",
      "749    36.94\n",
      "522    44.52\n",
      "Name: Strength, Length: 309, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = predictors\n",
    "y = target\n",
    "import sklearn.model_selection as model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7,test_size=0.3, random_state=101)\n",
    "print (\"X_train: \", X_train)\n",
    "print (\"y_train: \", y_train)\n",
    "print(\"X_test: \", X_test)\n",
    "print (\"y_test: \", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train the model on the training data using 50 epochs.\n",
    "\n",
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a loop to repeat the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics \n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = regression_model()\n",
    "mse_results=[]\n",
    "for x in range(50):\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    train_results = model.predict( X_test )\n",
    "    mse_results.append( mean_squared_error(y_test, train_results) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the list of mean square errors is 121.50265437726155\n",
      "Standard deviation of the list of mean square errors is 20.69587590901253\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of the list of mean square errors is % s\" % (statistics.mean( mse_results ) ))\n",
    "print(\"Standard deviation of the list of mean square errors is % s\" % ( statistics.stdev( mse_results )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Normalize the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat Part A but use a normalized version of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors_norm.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model_norm():\n",
    "    # create model\n",
    "    model_norm = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_norm = regression_model()\n",
    "mse_results_norm=[]\n",
    "for x in range(50):\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    train_results_norm = model.predict( X_test )\n",
    "    mse_results_norm.append( mean_squared_error(y_test, train_results_norm) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the mean of the mean squared errors compare to that from Step A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the list of mean square errors is 115.09650107787353\n",
      "Standard deviation of the list of mean square errors is 6.191113593932303\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of the list of mean square errors is % s\" % (statistics.mean( mse_results_norm ) ))\n",
    "print(\"Standard deviation of the list of mean square errors is % s\" % ( statistics.stdev( mse_results_norm )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Increase the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat Part B but use 100 epochs this time for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model_c():\n",
    "    # create model\n",
    "    model_c = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c = regression_model()\n",
    "mse_results_c=[]\n",
    "for x in range(50):\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    train_results_c = model.predict( X_test )\n",
    "    mse_results_c.append( mean_squared_error(y_test, train_results_c) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the list of mean square errors is 83.28499191304228\n",
      "Standard deviation of the list of mean square errors is 29.22540639830787\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of the list of mean square errors is % s\" % (statistics.mean( mse_results_c ) ))\n",
    "print(\"Standard deviation of the list of mean square errors is % s\" % ( statistics.stdev( mse_results_c )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Increase the number of hidden layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model_d():\n",
    "    # create model\n",
    "    model_d = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d = regression_model_d()\n",
    "mse_results_d=[]\n",
    "for x in range(50):\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    train_results_d = model.predict( X_test )\n",
    "    mse_results_d.append( mean_squared_error(y_test, train_results_d) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the list of mean square errors is 115.09650107787353\n",
      "Standard deviation of the list of mean square errors is 6.191113593932303\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of the list of mean square errors is % s\" % (statistics.mean( mse_results_norm ) ))\n",
    "print(\"Standard deviation of the list of mean square errors is % s\" % ( statistics.stdev( mse_results_norm )))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
